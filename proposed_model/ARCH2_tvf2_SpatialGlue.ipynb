{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_fold = 'C:/Users/AGNISH/Desktop/IITK/VSCode/SpatialGlue/Data/Mouse_Spleen/'\n",
    "gdata = sc.read_h5ad(file_fold + 'adata_RNA.h5ad')\n",
    "gdata.var_names_make_unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 2653 × 32285\n",
       "    var: 'gene_ids', 'feature_types', 'genome'\n",
       "    obsm: 'spatial'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_fold = 'C:/Users/AGNISH/Desktop/IITK/VSCode/SpatialGlue/Data/Mouse_Spleen/'\n",
    "pdata = sc.read_h5ad(file_fold + 'adata_Pro.h5ad')\n",
    "pdata.var_names_make_unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 2653 × 21\n",
       "    obsm: 'spatial'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalization\n",
    "sc.pp.highly_variable_genes(gdata, flavor=\"seurat_v3\", n_top_genes=3000)\n",
    "sc.pp.normalize_total(gdata, target_sum=1e4)\n",
    "sc.pp.log1p(gdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalization\n",
    "#sc.pp.highly_variable_genes(adata, flavor=\"seurat_v3\", n_top_genes=3000)\n",
    "sc.pp.normalize_total(pdata, target_sum=1e4)\n",
    "sc.pp.log1p(pdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 2653 × 32285\n",
       "    var: 'gene_ids', 'feature_types', 'genome', 'highly_variable', 'highly_variable_rank', 'means', 'variances', 'variances_norm'\n",
       "    uns: 'hvg', 'log1p'\n",
       "    obsm: 'spatial'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 2653 × 21\n",
       "    uns: 'log1p'\n",
       "    obsm: 'spatial'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdata"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: tensorflow\n",
      "Version: 2.12.0\n",
      "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
      "Home-page: https://www.tensorflow.org/\n",
      "Author: Google Inc.\n",
      "Author-email: packages@tensorflow.org\n",
      "License: Apache 2.0\n",
      "Location: c:\\users\\agnish\\.conda\\envs\\stagate\\lib\\site-packages\n",
      "Requires: tensorflow-intel\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.compat.v1 as v1\n",
    "\n",
    "\n",
    "class GATE():\n",
    "    def __init__(self, hidden_dims1, hidden_dims2,z_dim=30,alpha=0.8, nonlinear=True, weight_decay=0.0001):\n",
    "        self.n_layers1 = len(hidden_dims1) - 1\n",
    "        self.n_layers2 = len(hidden_dims2) - 1\n",
    "        self.alpha = alpha\n",
    "        self.W1, self.v1, self.prune_v1 = self.define_weights1(hidden_dims1, self.n_layers1)\n",
    "        self.W2, self.v2, self.prune_v2 = self.define_weights2(hidden_dims2, self.n_layers2)\n",
    "        self.C1 = {}\n",
    "        self.C2 = {}\n",
    "        self.prune_C1 = {}\n",
    "        self.prune_C2 = {}\n",
    "        self.nonlinear = nonlinear\n",
    "        self.weight_decay = weight_decay\n",
    "        self.z_dim = z_dim\n",
    "\n",
    "        # Decoder 1\n",
    "        self.W_dec1 = {}\n",
    "        for layer in range(self.n_layers1 - 1, -1, -1):\n",
    "            self.W_dec1[layer] = tf.Variable(tf.random.normal([hidden_dims1[layer+1], hidden_dims1[layer]]))\n",
    "\n",
    "        # Decoder 2\n",
    "        self.W_dec2 = {}\n",
    "        for layer in range(self.n_layers2 - 1, -1, -1):\n",
    "            self.W_dec2[layer] = tf.Variable(tf.random.normal([hidden_dims2[layer+1], hidden_dims2[layer]]))\n",
    "\n",
    "    def __call__(self, A1,A2 ,prune_A, X1,X2):\n",
    "        # Encoder 1\n",
    "        H1 = X1\n",
    "        for layer in range(self.n_layers1):\n",
    "            H1 = self.__encoder1(A1, prune_A, H1, layer)\n",
    "            if self.nonlinear:\n",
    "                if layer != self.n_layers1 - 1:\n",
    "                    H1 = tf.nn.elu(H1)\n",
    "\n",
    "        # Encoder 2\n",
    "        H2 = X2\n",
    "        for layer in range(self.n_layers2):\n",
    "            H2 = self.__encoder2(A2, prune_A, H2, layer)\n",
    "            if self.nonlinear:\n",
    "                if layer != self.n_layers2 - 1:\n",
    "                    H2 = tf.nn.elu(H2)\n",
    "        # Concatenate encoder outputs\n",
    "        H = tf.concat([H1, H2], axis=1)\n",
    "\n",
    "        # Call the third encoder\n",
    "        global latent_rep \n",
    "        H = self.__encoder3(H)\n",
    "        \n",
    "        latent_rep = H\n",
    "\n",
    "        temp=H\n",
    "        H1=temp\n",
    "        # Decoder 1\n",
    "        for layer in range(self.n_layers1 - 1, -1, -1):\n",
    "            H1 = self.__decoder1(H1, layer)\n",
    "            if self.nonlinear:\n",
    "                if layer != 0:\n",
    "                    H1 = tf.nn.elu(H1)\n",
    "        X1_ = H1\n",
    "\n",
    "        H2=temp\n",
    "        # Decoder 2\n",
    "        for layer1 in range(self.n_layers2 - 1, -1, -1):\n",
    "            H2 = self.__decoder2(H2, layer1)\n",
    "            if self.nonlinear:\n",
    "                if layer1 != 0:\n",
    "                    H2 = tf.nn.elu(H2)\n",
    "        X2_ = H2\n",
    "\n",
    "        # Loss calculation\n",
    "        features_loss = tf.sqrt(tf.reduce_sum(tf.pow(X1 - X1_, 2)))\n",
    "        features_loss += tf.sqrt(tf.reduce_sum(tf.pow(X2 - X2_, 2)))\n",
    "\n",
    "        weight_decay_loss = 0\n",
    "        for layer in range(self.n_layers1):\n",
    "            weight_decay_loss += tf.multiply(tf.nn.l2_loss(self.W1[layer]), self.weight_decay, name='weight_loss')\n",
    "        for layer in range(self.n_layers2):\n",
    "            weight_decay_loss += tf.multiply(tf.nn.l2_loss(self.W2[layer]), self.weight_decay, name='weight_loss')\n",
    "        for layer in range(self.n_layers1):\n",
    "            weight_decay_loss += tf.multiply(tf.nn.l2_loss(self.W_dec1[layer]), self.weight_decay, name='weight_loss')\n",
    "        for layer in range(self.n_layers2):\n",
    "            weight_decay_loss += tf.multiply(tf.nn.l2_loss(self.W_dec2[layer]), self.weight_decay, name='weight_loss')\n",
    "\n",
    "        # Total loss\n",
    "        self.loss = features_loss + weight_decay_loss\n",
    "\n",
    "        if self.alpha == 0:\n",
    "            self.Att_l = {'C1': self.C1, 'C2': self.C2}\n",
    "        else:\n",
    "            self.Att_l = {'C1': self.C1, 'C2': self.C2, 'prune_C1': self.prune_C1, 'prune_C2': self.prune_C2}\n",
    "        return self.loss, latent_rep, self.Att_l, X1_, X2_\n",
    "    \n",
    "    def __encoder1(self, A, prune_A, H, layer):\n",
    "        print('enc1 = ',H)\n",
    "        H = tf.matmul(H, self.W1[layer])\n",
    "        if layer == self.n_layers1 - 1:\n",
    "            return H\n",
    "        self.C1[layer] = self.graph_attention_layer(A, H, self.v1[layer], layer)\n",
    "        if self.alpha == 0:\n",
    "            return tf.sparse.sparse_dense_matmul(self.C1[layer], H)\n",
    "        else:\n",
    "            self.prune_C1[layer] = self.graph_attention_layer(prune_A, H, self.prune_v1[layer], layer)\n",
    "            return (1 - self.alpha) * tf.sparse.sparse_dense_matmul(self.C1[layer], H) + self.alpha * tf.sparse.sparse_dense_matmul(\n",
    "                self.prune_C1[layer], H)\n",
    "        \n",
    "        \n",
    "\n",
    "    def __encoder2(self, A, prune_A, H, layer):\n",
    "        print('enc2 = ',H)\n",
    "        H = tf.matmul(H, self.W2[layer])\n",
    "        if layer == self.n_layers2 - 1:\n",
    "            return H\n",
    "        self.C2[layer] = self.graph_attention_layer(A, H, self.v2[layer], layer)\n",
    "        if self.alpha == 0:\n",
    "            return tf.sparse.sparse_dense_matmul(self.C2[layer], H)\n",
    "        else:\n",
    "            self.prune_C2[layer] = self.graph_attention_layer(prune_A, H, self.prune_v2[layer], layer)\n",
    "            return (1 - self.alpha) * tf.sparse.sparse_dense_matmul(self.C2[layer], H) + self.alpha * tf.sparse.sparse_dense_matmul(\n",
    "                self.prune_C2[layer], H)\n",
    "    \n",
    "    def __decoder1(self, H, layer):\n",
    "        print('dec1 = ',H)\n",
    "        H = tf.matmul(H, self.W1[layer], transpose_b=True)\n",
    "        if layer == 0:\n",
    "\n",
    "            return H\n",
    "        if self.alpha == 0:\n",
    "\n",
    "            return tf.sparse.sparse_dense_matmul(self.C1[layer-1], H)\n",
    "        else:\n",
    "\n",
    "            return (1 - self.alpha) * tf.sparse.sparse_dense_matmul(self.C1[layer-1], H) + self.alpha * tf.sparse.sparse_dense_matmul(\n",
    "                self.prune_C1[layer-1], H)\n",
    "        \n",
    "    def __decoder2(self, H, layer):\n",
    "        print('dec2 = ',H)\n",
    "        H = tf.matmul(H, self.W2[layer], transpose_b=True)\n",
    "        if layer == 0:\n",
    "\n",
    "            return H\n",
    "        if self.alpha == 0:\n",
    "            return tf.sparse.sparse_dense_matmul(self.C2[layer-1], H)\n",
    "        \n",
    "        else:\n",
    "\n",
    "            return (1 - self.alpha) * tf.sparse.sparse_dense_matmul(self.C2[layer-1], H) + self.alpha * tf.sparse.sparse_dense_matmul(\n",
    "                self.prune_C2[layer-1], H)\n",
    "        \n",
    "\n",
    "    def __encoder3(self, H):\n",
    "        print('enc3 = ',H)\n",
    "        H = tf.keras.layers.Dense(self.z_dim)(H)\n",
    "        print('LATENT = ',H)\n",
    "        return H\n",
    "\n",
    "\n",
    "    def define_weights1(self,hidden_dims,n_layers):\n",
    "        W = {}\n",
    "        #print('TOTAL LEYRS = ',n_layers)\n",
    "        #n_layers=len(n_layers)-1\n",
    "        print('n_layers gene = ',n_layers)\n",
    "        print('Hidden dim gene = ',hidden_dims)\n",
    "\n",
    "        for i in range(n_layers):\n",
    "            W[i] = v1.get_variable(\"W%s\" % i, shape=(hidden_dims[i], hidden_dims[i+1]))\n",
    "\n",
    "        Ws_att = {}\n",
    "        for i in range(n_layers-1):\n",
    "            V= {}\n",
    "            V[0] = v1.get_variable(\"V%s_0\" % i, shape=(hidden_dims[i+1], 1))\n",
    "            V[1] = v1.get_variable(\"V%s_1\" % i, shape=(hidden_dims[i+1], 1))\n",
    "\n",
    "            Ws_att[i] = V\n",
    "        if self.alpha == 0:\n",
    "            return W, Ws_att, None\n",
    "        prune_Ws_att = {}\n",
    "        for i in range(n_layers-1):\n",
    "            prune_V = {}\n",
    "            prune_V[0] = v1.get_variable(\"prune_V%s_0\" % i, shape=(hidden_dims[i+1], 1))\n",
    "            prune_V[1] = v1.get_variable(\"prune_V%s_1\" % i, shape=(hidden_dims[i+1], 1))\n",
    "\n",
    "            prune_Ws_att[i] = prune_V\n",
    "\n",
    "        return W, Ws_att, prune_Ws_att\n",
    "    \n",
    "    def define_weights2(self,hidden_dims,n_layers):\n",
    "        w = {}\n",
    "        #print('TOTAL LEYRS = ',n_layers)\n",
    "        #n_layers=len(n_layers)-1\n",
    "        print('n_layers protein = ',n_layers)\n",
    "        print('Hidden dim protein = ',hidden_dims)\n",
    "\n",
    "        for i in range(n_layers):\n",
    "            w[i] = v1.get_variable(\"w%s\" % i, shape=(hidden_dims[i], hidden_dims[i+1]))\n",
    "\n",
    "        ws_att = {}\n",
    "        for i in range(n_layers-1):\n",
    "            v = {}\n",
    "            v[0] = v1.get_variable(\"v%s_0\" % i, shape=(hidden_dims[i+1], 1))\n",
    "            v[1] = v1.get_variable(\"v%s_1\" % i, shape=(hidden_dims[i+1], 1))\n",
    "\n",
    "            ws_att[i] = v\n",
    "        if self.alpha == 0:\n",
    "            return w, ws_att, None\n",
    "        prune_ws_att = {}\n",
    "        for i in range(n_layers-1):\n",
    "            prune_v = {}\n",
    "            prune_v[0] = v1.get_variable(\"prune_v%s_0\" % i, shape=(hidden_dims[i+1], 1))\n",
    "            prune_v[1] = v1.get_variable(\"prune_v%s_1\" % i, shape=(hidden_dims[i+1], 1))\n",
    "\n",
    "            prune_ws_att[i] = prune_v\n",
    "\n",
    "        return w, ws_att, prune_ws_att\n",
    "    \n",
    "\n",
    "\n",
    "    def graph_attention_layer(self, A, M, v, layer):\n",
    "\n",
    "        with v1.variable_scope(\"layer_%s\" % layer):\n",
    "            f1 = tf.matmul(M, v[0])\n",
    "            f1 = A * f1\n",
    "            f2 = tf.matmul(M, v[1])\n",
    "            f2 = A * tf.transpose(f2, [1, 0])\n",
    "            logits = v1.sparse_add(f1, f2)\n",
    "\n",
    "            unnormalized_attentions = tf.SparseTensor(indices=logits.indices,\n",
    "                                         values=tf.nn.sigmoid(logits.values),\n",
    "                                         dense_shape=logits.dense_shape)\n",
    "            attentions = v1.sparse_softmax(unnormalized_attentions)\n",
    "\n",
    "            attentions = tf.SparseTensor(indices=attentions.indices,\n",
    "                                         values=attentions.values,\n",
    "                                         dense_shape=attentions.dense_shape)\n",
    "\n",
    "            return attentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import scipy.sparse as sp\n",
    "import numpy as np\n",
    "#from .model import GATE\n",
    "import tensorflow.compat.v1 as v1\n",
    "from tqdm import tqdm\n",
    "\n",
    "class STAGATE():\n",
    "\n",
    "    def __init__(self, hidden_dims1, hidden_dims2,z_dim=30, alpha=0, n_epochs=500, lr=0.0001, \n",
    "                 gradient_clipping=5, nonlinear=True, weight_decay=0.0001, \n",
    "                 verbose=True, random_seed=2020,\n",
    "                 ):\n",
    "        \n",
    "        np.random.seed(random_seed)\n",
    "        tf.random.set_seed(random_seed)\n",
    "        self.loss_list = []\n",
    "        self.lr = lr\n",
    "        self.n_epochs = n_epochs\n",
    "        self.gradient_clipping = gradient_clipping\n",
    "        self.build_placeholders()\n",
    "        self.verbose = verbose\n",
    "        self.alpha = alpha\n",
    "           \n",
    "\n",
    "        self.gate = GATE(hidden_dims1,hidden_dims2,z_dim,alpha, nonlinear, weight_decay)\n",
    "        self.loss, self.H, self.C, self.ReX1, self.ReX2 = self.gate(self.A1,self.A2, self.prune_A, self.X1,self.X2)\n",
    "        #print(self.loss, self.H, self.C, self.ReX1, self.ReX2,sep='\\n')\n",
    "\n",
    "        self.optimize(self.loss)\n",
    "        self.build_session()\n",
    "\n",
    "    def build_placeholders(self):\n",
    "        self.A1 = v1.sparse_placeholder(dtype=tf.float32)\n",
    "        self.A2 = v1.sparse_placeholder(dtype=tf.float32)\n",
    "        self.prune_A = v1.sparse_placeholder(dtype=tf.float32)\n",
    "        self.X1 = v1.placeholder(dtype=tf.float32)\n",
    "        self.X2 = v1.placeholder(dtype=tf.float32)\n",
    "\n",
    "\n",
    "    def build_session(self, gpu= True):\n",
    "        config = v1.ConfigProto()\n",
    "        config.gpu_options.allow_growth = True\n",
    "        if gpu == False:\n",
    "            config.intra_op_parallelism_threads = 0\n",
    "            config.inter_op_parallelism_threads = 0\n",
    "        self.session = v1.Session(config=config)\n",
    "        self.session.run([v1.global_variables_initializer(), v1.local_variables_initializer()])\n",
    "\n",
    "    def optimize(self, loss):\n",
    "        optimizer = v1.train.AdamOptimizer(learning_rate=self.lr)\n",
    "        gradients, variables = zip(*optimizer.compute_gradients(loss))\n",
    "        gradients, _ = tf.clip_by_global_norm(gradients, self.gradient_clipping)\n",
    "        self.train_op = optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "    def __call__(self, A1, A2, prune_A, X1, X2):\n",
    "        for epoch in range(self.n_epochs):\n",
    "            self.run_epoch(epoch, A1, A2, prune_A, X1, X2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def run_epoch(self, epoch, A1,A2 ,prune_A, X1,X2):\n",
    "\n",
    "        loss, _ = self.session.run([self.loss, self.train_op],\n",
    "                           feed_dict={self.A1: A1,\n",
    "                                      self.A2: A2,\n",
    "                                      self.prune_A: prune_A,\n",
    "                                      self.X1: X1,\n",
    "                                      self.X2: X2})\n",
    "\n",
    "        self.loss_list.append(loss)\n",
    "        if self.verbose:\n",
    "            print(\"Epoch: %s, Loss: %.4f\" % (epoch, loss))\n",
    "            \n",
    "        return loss\n",
    "\n",
    "    def infer(self, A1,A2, prune_A, X1,X2):\n",
    "        global C\n",
    "        H, C, ReX1, ReX2 = self.session.run([self.H, self.C, self.ReX1, self.ReX2],\n",
    "                                    feed_dict={self.A1: A1,\n",
    "                                               self.A2: A2,\n",
    "                                               self.prune_A: prune_A,\n",
    "                                               self.X1: X1,\n",
    "                                               self.X2: X2})\n",
    "\n",
    "        \n",
    "        return H, self.Conbine_Atten_l(C['C1']), self.loss_list, ReX1,ReX2\n",
    "\n",
    "    def Conbine_Atten_l(self, input):\n",
    "        if self.alpha == 0:\n",
    "            return [sp.coo_matrix((input[layer][1], (input[layer][0][:, 0], input[layer][0][:, 1])), shape=(input[layer][2][0], input[layer][2][1])) for layer in input]\n",
    "        else:\n",
    "            Att_C = [sp.coo_matrix((input['C'][layer][1], (input['C'][layer][0][:, 0], input['C'][layer][0][:, 1])), shape=(input['C'][layer][2][0], input['C'][layer][2][1])) for layer in input['C']]\n",
    "            Att_pruneC = [sp.coo_matrix((input['prune_C'][layer][1], (input['prune_C'][layer][0][:, 0], input['prune_C'][layer][0][:, 1])), shape=(input['prune_C'][layer][2][0], input['prune_C'][layer][2][1])) for layer in input['prune_C']]\n",
    "            return [self.alpha*Att_pruneC[layer] + (1-self.alpha)*Att_C[layer] for layer in input['C']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "#from .STAGATE import STAGATE\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "\n",
    "def train_STAGATE(adata1,adata2, \n",
    "                hidden_dims1=[512, 30],hidden_dims2=[512, 30],z_dim=30, alpha=0, n_epochs=500, lr=0.0001, key_added='MY_ARCH',\n",
    "                gradient_clipping=5, nonlinear=True, weight_decay=0.0001,verbose=True, \n",
    "                random_seed=2020, pre_labels=None, pre_resolution=0.2,\n",
    "                save_attention=False, save_loss=False, save_reconstrction=False\n",
    "                ):\n",
    "    \"\"\"\\\n",
    "    Training graph attention auto-encoder.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    adata\n",
    "        AnnData object of scanpy package.\n",
    "    hidden_dims\n",
    "        The dimension of the encoder.\n",
    "    alpha\n",
    "        The weight of cell type-aware spatial neighbor network.\n",
    "    n_epochs\n",
    "        Number of total epochs in training.\n",
    "    lr\n",
    "        Learning rate for AdamOptimizer.\n",
    "    key_added\n",
    "        The latent embeddings are saved in adata.obsm[key_added].\n",
    "    gradient_clipping\n",
    "        Gradient Clipping.\n",
    "    nonlinear\n",
    "        If True, the nonlinear avtivation is performed.\n",
    "    weight_decay\n",
    "        Weight decay for AdamOptimizer.\n",
    "    pre_labels\n",
    "        The key in adata.obs for the manually designate the pre-clustering results. Only used when alpha>0.\n",
    "    pre_resolution\n",
    "        The resolution parameter of sc.tl.louvain for the pre-clustering. Only used when alpha>0 and per_labels==None.\n",
    "    save_attention\n",
    "        If True, the weights of the attention layers are saved in adata.uns['STAGATE_attention']\n",
    "    save_loss\n",
    "        If True, the training loss is saved in adata.uns['STAGATE_loss'].\n",
    "    save_reconstrction\n",
    "        If True, the reconstructed expression profiles are saved in adata.layers['STAGATE_ReX'].\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    AnnData\n",
    "    \"\"\"\n",
    "\n",
    "    #tf.reset_default_graph()\n",
    "    np.random.seed(random_seed)\n",
    "    tf.random.set_seed(random_seed)\n",
    "\n",
    "    if 'highly_variable' in adata1.var.columns:\n",
    "        adata_Vars1 =  adata1[:, adata1.var['highly_variable']]\n",
    "    else:\n",
    "        adata_Vars1 = adata1\n",
    "    X1 = pd.DataFrame(adata_Vars1.X[:, ].toarray(), index=adata_Vars1.obs.index, columns=adata_Vars1.var.index)\n",
    "\n",
    "    \n",
    "    if 'highly_variable' in adata2.var.columns:\n",
    "        adata_Vars2 =  adata2[:, adata2.var['highly_variable']]\n",
    "    else:\n",
    "        adata_Vars2 = adata2\n",
    "    X2 = pd.DataFrame(adata_Vars2.X[:, ], index=adata_Vars2.obs.index, columns=adata_Vars2.var.index)\n",
    "\n",
    "    if verbose:\n",
    "        print('Size of Input for gene data : ', adata_Vars1.shape)\n",
    "        print('Size of Input for protein data : ',adata_Vars2.shape)\n",
    "\n",
    "\n",
    "\n",
    "    cells1 = np.array(X1.index)\n",
    "    cells_id_tran1 = dict(zip(cells1, range(cells1.shape[0])))\n",
    "    if 'Spatial_Net' not in adata1.uns.keys():\n",
    "        raise ValueError(\"Spatial_Net is not existed! Run Cal_Spatial_Net first!\")\n",
    "\n",
    "    Spatial_Net1 = adata1.uns['Spatial_Net']\n",
    "    G_df1 = Spatial_Net1.copy()\n",
    "    G_df1['Cell1'] = G_df1['Cell1'].map(cells_id_tran1)\n",
    "    G_df1['Cell2'] = G_df1['Cell2'].map(cells_id_tran1)\n",
    "    G1 = sp.coo_matrix((np.ones(G_df1.shape[0]), (G_df1['Cell1'], G_df1['Cell2'])), shape=(adata1.n_obs, adata1.n_obs))\n",
    "    global G_tf1\n",
    "    G_tf1 = prepare_graph_data(G1)\n",
    "\n",
    "    cells2 = np.array(X2.index)\n",
    "    cells_id_tran2 = dict(zip(cells2, range(cells2.shape[0])))\n",
    "    if 'Spatial_Net' not in adata2.uns.keys():\n",
    "        raise ValueError(\"Spatial_Net is not existed! Run Cal_Spatial_Net first!\")\n",
    "    Spatial_Net2 = adata1.uns['Spatial_Net']\n",
    "    G_df2 = Spatial_Net2.copy()\n",
    "    G_df2['Cell1'] = G_df2['Cell1'].map(cells_id_tran2)\n",
    "    G_df2['Cell2'] = G_df2['Cell2'].map(cells_id_tran2)\n",
    "    G2 = sp.coo_matrix((np.ones(G_df2.shape[0]), (G_df2['Cell1'], G_df2['Cell2'])), shape=(adata2.n_obs, adata2.n_obs))\n",
    "    global G_tf2\n",
    "    G_tf2 = prepare_graph_data(G2)\n",
    "\n",
    "    tf.compat.v1.disable_eager_execution()\n",
    "    trainer = STAGATE(hidden_dims1=[X1.shape[1]] + hidden_dims1,hidden_dims2=[X2.shape[1]] + hidden_dims2, z_dim=z_dim,alpha=alpha, \n",
    "                    n_epochs=n_epochs, lr=lr, gradient_clipping=gradient_clipping, \n",
    "                    nonlinear=nonlinear,weight_decay=weight_decay, verbose=verbose, \n",
    "                    random_seed=random_seed                    \n",
    "                    )\n",
    "    \n",
    "\n",
    "    print(\"START TRAIN\")\n",
    "    \n",
    "    #explain the code from here\n",
    "    if alpha == 0:\n",
    "        trainer(G_tf1, G_tf2, G_tf1, X1,X2)\n",
    "        embeddings, attentions, loss, ReX1, ReX2= trainer.infer(G_tf1, G_tf2, G_tf1, X1,X2)\n",
    "    else:\n",
    "        G_df1 = Spatial_Net1.copy()\n",
    "        if pre_labels==None:\n",
    "            if verbose:\n",
    "                print('------Pre-clustering adata1 using louvain with resolution=%.2f' %pre_resolution)\n",
    "            sc.tl.pca(adata1, svd_solver='arpack')\n",
    "            sc.pp.neighbors(adata1)\n",
    "            sc.tl.louvain(adata1, resolution=pre_resolution, key_added='expression_louvain_label')\n",
    "            pre_labels = 'expression_louvain_label'\n",
    "        prune_G_df = prune_spatial_Net(G_df1, adata1.obs[pre_labels])\n",
    "        prune_G_df['Cell1'] = prune_G_df['Cell1'].map(cells_id_tran1)\n",
    "        prune_G_df['Cell2'] = prune_G_df['Cell2'].map(cells_id_tran1)\n",
    "        prune_G = sp.coo_matrix((np.ones(prune_G_df.shape[0]), (prune_G_df['Cell1'], prune_G_df['Cell2'])))\n",
    "        prune_G_tf = prepare_graph_data(prune_G)\n",
    "        prune_G_tf = (prune_G_tf[0], prune_G_tf[1], G_tf1[2])\n",
    "        trainer(G_tf1, prune_G_tf, X1)\n",
    "        embeddings, attentions, loss, ReX1, ReX2 = trainer.infer(G_tf1,G_tf2, prune_G_tf, X1,X2)\n",
    "\n",
    "    global df\n",
    "    cell_reps = pd.DataFrame(embeddings)\n",
    "    df=cell_reps\n",
    "    cell_reps.index = cells1\n",
    "\n",
    "    adata1.obsm[key_added] = cell_reps.loc[adata1.obs_names, ].values\n",
    "    if save_attention:\n",
    "        adata1.uns['arch_attention'] = attentions\n",
    "    if save_loss:\n",
    "        adata1.uns['arch_loss'] = loss\n",
    "    if save_reconstrction:\n",
    "        ReX1 = pd.DataFrame(ReX1, index=X1.index, columns=X1.columns)\n",
    "        ReX1[ReX1<0] = 0\n",
    "        adata1.layers['arch_ReX1'] = ReX1.values\n",
    "        ReX2 = pd.DataFrame(ReX2, index=X2.index, columns=X2.columns)\n",
    "        ReX2[ReX2<0] = 0\n",
    "        adata2.layers['archE_ReX2'] = ReX2.values\n",
    "\n",
    "    return adata1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def prune_spatial_Net(Graph_df, label):\n",
    "    print('------Pruning the graph...')\n",
    "    print('%d edges before pruning.' %Graph_df.shape[0])\n",
    "    pro_labels_dict = dict(zip(list(label.index), label))\n",
    "    Graph_df['Cell1_label'] = Graph_df['Cell1'].map(pro_labels_dict)\n",
    "    Graph_df['Cell2_label'] = Graph_df['Cell2'].map(pro_labels_dict)\n",
    "    Graph_df = Graph_df.loc[Graph_df['Cell1_label']==Graph_df['Cell2_label'],]\n",
    "    print('%d edges after pruning.' %Graph_df.shape[0])\n",
    "    return Graph_df\n",
    "\n",
    "\n",
    "def prepare_graph_data(adj):\n",
    "    # adapted from preprocess_adj_bias\n",
    "    num_nodes = adj.shape[0]\n",
    "    adj = adj + sp.eye(num_nodes)# self-loop\n",
    "    #data =  adj.tocoo().data\n",
    "    #adj[adj > 0.0] = 1.0\n",
    "    if not sp.isspmatrix_coo(adj):\n",
    "        adj = adj.tocoo()\n",
    "    adj = adj.astype(np.float32)\n",
    "    indices = np.vstack((adj.col, adj.row)).transpose()\n",
    "    return (indices, adj.data, adj.shape)\n",
    "\n",
    "def recovery_Imputed_Count(adata, size_factor):\n",
    "    assert('ReX1' in adata.uns)\n",
    "    temp_df = adata.uns['ReX1'].copy()\n",
    "    sf = size_factor.loc[temp_df.index]\n",
    "    temp_df = np.expm1(temp_df)\n",
    "    temp_df = (temp_df.T * sf).T\n",
    "    adata.uns['ReX_Count1'] = temp_df\n",
    "    \n",
    "    assert('ReX2' in adata.uns)\n",
    "    temp_df = adata.uns['ReX2'].copy()\n",
    "    sf = size_factor.loc[temp_df.index]\n",
    "    temp_df = np.expm1(temp_df)\n",
    "    temp_df = (temp_df.T * sf).T\n",
    "    adata.uns['ReX_Count2'] = temp_df\n",
    "\n",
    "    return adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.neighbors\n",
    "\n",
    "\n",
    "def Cal_Spatial_Net(adata, rad_cutoff=None, k_cutoff=None, model='Radius', verbose=True):\n",
    "    \"\"\"\\\n",
    "    Construct the spatial neighbor networks.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    adata\n",
    "        AnnData object of scanpy package.\n",
    "    rad_cutoff\n",
    "        radius cutoff when model='Radius'\n",
    "    k_cutoff\n",
    "        The number of nearest neighbors when model='KNN'\n",
    "    model\n",
    "        The network construction model. When model=='Radius', the spot is connected to spots whose distance is less than rad_cutoff. When model=='KNN', the spot is connected to its first k_cutoff nearest neighbors.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    The spatial networks are saved in adata.uns['Spatial_Net']\n",
    "    \"\"\"\n",
    "\n",
    "    assert(model in ['Radius', 'KNN'])\n",
    "    if verbose:\n",
    "        print('------Calculating spatial graph...')\n",
    "    coor = pd.DataFrame(adata.obsm['spatial'])\n",
    "    coor.index = adata.obs.index\n",
    "    coor.columns = ['imagerow', 'imagecol']\n",
    "\n",
    "    if model == 'Radius':\n",
    "        nbrs = sklearn.neighbors.NearestNeighbors(radius=rad_cutoff).fit(coor)\n",
    "        distances, indices = nbrs.radius_neighbors(coor, return_distance=True)\n",
    "        KNN_list = []\n",
    "        for it in range(indices.shape[0]):\n",
    "            KNN_list.append(pd.DataFrame(zip([it]*indices[it].shape[0], indices[it], distances[it])))\n",
    "    \n",
    "    if model == 'KNN':\n",
    "        nbrs = sklearn.neighbors.NearestNeighbors(n_neighbors=k_cutoff+1).fit(coor)\n",
    "        distances, indices = nbrs.kneighbors(coor)\n",
    "        KNN_list = []\n",
    "        for it in range(indices.shape[0]):\n",
    "            KNN_list.append(pd.DataFrame(zip([it]*indices.shape[1],indices[it,:], distances[it,:])))\n",
    "\n",
    "    KNN_df = pd.concat(KNN_list)\n",
    "    KNN_df.columns = ['Cell1', 'Cell2', 'Distance']\n",
    "\n",
    "    Spatial_Net = KNN_df.copy()\n",
    "    Spatial_Net = Spatial_Net.loc[Spatial_Net['Distance']>0,]\n",
    "    id_cell_trans = dict(zip(range(coor.shape[0]), np.array(coor.index), ))\n",
    "    Spatial_Net['Cell1'] = Spatial_Net['Cell1'].map(id_cell_trans)\n",
    "    Spatial_Net['Cell2'] = Spatial_Net['Cell2'].map(id_cell_trans)\n",
    "    if verbose:\n",
    "        print('The graph contains %d edges, %d cells.' %(Spatial_Net.shape[0], adata.n_obs))\n",
    "        print('%.4f neighbors per cell on average.' %(Spatial_Net.shape[0]/adata.n_obs))\n",
    "\n",
    "    adata.uns['Spatial_Net'] = Spatial_Net\n",
    "\n",
    "\n",
    "def Cal_Spatial_Net_3D(adata, rad_cutoff_2D, rad_cutoff_Zaxis,\n",
    "                       key_section='Section_id', section_order=None, verbose=True):\n",
    "    \"\"\"\\\n",
    "    Construct the spatial neighbor networks.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    adata\n",
    "        AnnData object of scanpy package.\n",
    "    rad_cutoff_2D\n",
    "        radius cutoff for 2D SNN construction.\n",
    "    rad_cutoff_Zaxis\n",
    "        radius cutoff for 2D SNN construction for consturcting SNNs between adjacent sections.\n",
    "    key_section\n",
    "        The columns names of section_ID in adata.obs.\n",
    "    section_order\n",
    "        The order of sections. The SNNs between adjacent sections are constructed according to this order.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    The 3D spatial networks are saved in adata.uns['Spatial_Net'].\n",
    "    \"\"\"\n",
    "    adata.uns['Spatial_Net_2D'] = pd.DataFrame()\n",
    "    adata.uns['Spatial_Net_Zaxis'] = pd.DataFrame()\n",
    "    num_section = np.unique(adata.obs[key_section]).shape[0]\n",
    "    if verbose:\n",
    "        print('Radius used for 2D SNN:', rad_cutoff_2D)\n",
    "        print('Radius used for SNN between sections:', rad_cutoff_Zaxis)\n",
    "    for temp_section in np.unique(adata.obs[key_section]):\n",
    "        if verbose:\n",
    "            print('------Calculating 2D SNN of section ', temp_section)\n",
    "        temp_adata = adata[adata.obs[key_section] == temp_section, ]\n",
    "        Cal_Spatial_Net(\n",
    "            temp_adata, rad_cutoff=rad_cutoff_2D, verbose=False)\n",
    "        temp_adata.uns['Spatial_Net']['SNN'] = temp_section\n",
    "        if verbose:\n",
    "            print('This graph contains %d edges, %d cells.' %\n",
    "                  (temp_adata.uns['Spatial_Net'].shape[0], temp_adata.n_obs))\n",
    "            print('%.4f neighbors per cell on average.' %\n",
    "                  (temp_adata.uns['Spatial_Net'].shape[0]/temp_adata.n_obs))\n",
    "        adata.uns['Spatial_Net_2D'] = pd.concat(\n",
    "            [adata.uns['Spatial_Net_2D'], temp_adata.uns['Spatial_Net']])\n",
    "    for it in range(num_section-1):\n",
    "        section_1 = section_order[it]\n",
    "        section_2 = section_order[it+1]\n",
    "        if verbose:\n",
    "            print('------Calculating SNN between adjacent section %s and %s.' %\n",
    "                  (section_1, section_2))\n",
    "        Z_Net_ID = section_1+'-'+section_2\n",
    "        temp_adata = adata[adata.obs[key_section].isin(\n",
    "            [section_1, section_2]), ]\n",
    "        Cal_Spatial_Net(\n",
    "            temp_adata, rad_cutoff=rad_cutoff_Zaxis, verbose=False)\n",
    "        spot_section_trans = dict(\n",
    "            zip(temp_adata.obs.index, temp_adata.obs[key_section]))\n",
    "        temp_adata.uns['Spatial_Net']['Section_id_1'] = temp_adata.uns['Spatial_Net']['Cell1'].map(\n",
    "            spot_section_trans)\n",
    "        temp_adata.uns['Spatial_Net']['Section_id_2'] = temp_adata.uns['Spatial_Net']['Cell2'].map(\n",
    "            spot_section_trans)\n",
    "        used_edge = temp_adata.uns['Spatial_Net'].apply(\n",
    "            lambda x: x['Section_id_1'] != x['Section_id_2'], axis=1)\n",
    "        temp_adata.uns['Spatial_Net'] = temp_adata.uns['Spatial_Net'].loc[used_edge, ]\n",
    "        temp_adata.uns['Spatial_Net'] = temp_adata.uns['Spatial_Net'].loc[:, [\n",
    "            'Cell1', 'Cell2', 'Distance']]\n",
    "        temp_adata.uns['Spatial_Net']['SNN'] = Z_Net_ID\n",
    "        if verbose:\n",
    "            print('This graph contains %d edges, %d cells.' %\n",
    "                  (temp_adata.uns['Spatial_Net'].shape[0], temp_adata.n_obs))\n",
    "            print('%.4f neighbors per cell on average.' %\n",
    "                  (temp_adata.uns['Spatial_Net'].shape[0]/temp_adata.n_obs))\n",
    "        adata.uns['Spatial_Net_Zaxis'] = pd.concat(\n",
    "            [adata.uns['Spatial_Net_Zaxis'], temp_adata.uns['Spatial_Net']])\n",
    "    adata.uns['Spatial_Net'] = pd.concat(\n",
    "        [adata.uns['Spatial_Net_2D'], adata.uns['Spatial_Net_Zaxis']])\n",
    "    if verbose:\n",
    "        print('3D SNN contains %d edges, %d cells.' %\n",
    "            (adata.uns['Spatial_Net'].shape[0], adata.n_obs))\n",
    "        print('%.4f neighbors per cell on average.' %\n",
    "            (adata.uns['Spatial_Net'].shape[0]/adata.n_obs))\n",
    "\n",
    "def Stats_Spatial_Net(adata):\n",
    "    import matplotlib.pyplot as plt\n",
    "    Num_edge = adata.uns['Spatial_Net']['Cell1'].shape[0]\n",
    "    Mean_edge = Num_edge/adata.shape[0]\n",
    "    plot_df = pd.value_counts(pd.value_counts(adata.uns['Spatial_Net']['Cell1']))\n",
    "    plot_df = plot_df/adata.shape[0]\n",
    "    fig, ax = plt.subplots(figsize=[3,2])\n",
    "    plt.ylabel('Percentage')\n",
    "    plt.xlabel('')\n",
    "    plt.title('Number of Neighbors (Mean=%.2f)'%Mean_edge)\n",
    "    ax.bar(plot_df.index, plot_df)\n",
    "\n",
    "def mclust_R(adata, num_cluster, modelNames='EEE', used_obsm='STAGATE', random_seed=2020):\n",
    "    \"\"\"\\\n",
    "    Clustering using the mclust algorithm.\n",
    "    The parameters are the same as those in the R package mclust.\n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(random_seed)\n",
    "    import rpy2.robjects as robjects\n",
    "    robjects.r.library(\"mclust\")\n",
    "\n",
    "    import rpy2.robjects.numpy2ri\n",
    "    rpy2.robjects.numpy2ri.activate()\n",
    "    r_random_seed = robjects.r['set.seed']\n",
    "    r_random_seed(random_seed)\n",
    "    rmclust = robjects.r['Mclust']\n",
    "\n",
    "    res = rmclust(rpy2.robjects.numpy2ri.numpy2rpy(adata.obsm[used_obsm]), num_cluster, modelNames)\n",
    "    mclust_res = np.array(res[-2])\n",
    "\n",
    "    adata.obs['mclust'] = mclust_res\n",
    "    adata.obs['mclust'] = adata.obs['mclust'].astype('int')\n",
    "    adata.obs['mclust'] = adata.obs['mclust'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Calculating spatial graph...\n",
      "The graph contains 6829234 edges, 2653 cells.\n",
      "2574.1553 neighbors per cell on average.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Cal_Spatial_Net(gdata, rad_cutoff=100)\n",
    "Stats_Spatial_Net(gdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Calculating spatial graph...\n",
      "The graph contains 6829234 edges, 2653 cells.\n",
      "2574.1553 neighbors per cell on average.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Cal_Spatial_Net(pdata, rad_cutoff=100)\n",
    "Stats_Spatial_Net(pdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Input for gene data :  (2653, 3000)\n",
      "Size of Input for protein data :  (2653, 21)\n",
      "n_layers gene =  2\n",
      "Hidden dim gene =  [3000, 512, 30]\n",
      "n_layers protein =  2\n",
      "Hidden dim protein =  [21, 512, 30]\n",
      "enc1 =  Tensor(\"Placeholder_9:0\", dtype=float32)\n",
      "enc1 =  Tensor(\"Elu:0\", shape=(None, None), dtype=float32)\n",
      "enc2 =  Tensor(\"Placeholder_10:0\", dtype=float32)\n",
      "enc2 =  Tensor(\"Elu_1:0\", shape=(None, None), dtype=float32)\n",
      "enc3 =  Tensor(\"concat:0\", shape=(None, 60), dtype=float32)\n",
      "LATENT =  Tensor(\"dense/BiasAdd:0\", shape=(None, 30), dtype=float32)\n",
      "dec1 =  Tensor(\"dense/BiasAdd:0\", shape=(None, 30), dtype=float32)\n",
      "dec1 =  Tensor(\"Elu_2:0\", shape=(None, 512), dtype=float32)\n",
      "dec2 =  Tensor(\"dense/BiasAdd:0\", shape=(None, 30), dtype=float32)\n",
      "dec2 =  Tensor(\"Elu_3:0\", shape=(None, 512), dtype=float32)\n",
      "START TRAIN\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'gradients/SparseTensorDenseMatMul_1/SparseTensorDenseMatMul_grad/GatherV2_1' defined at (most recent call last):\n    File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n      app.start()\n    File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 725, in start\n      self.io_loop.start()\n    File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3006, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3061, in _run_cell\n      result = runner(coro)\n    File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3266, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3445, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3505, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\AGNISH\\AppData\\Local\\Temp\\ipykernel_9128\\2186767892.py\", line 1, in <module>\n      gdata = train_STAGATE(gdata,pdata,n_epochs=500, alpha=0,save_attention=True, save_loss=True)\n    File \"C:\\Users\\AGNISH\\AppData\\Local\\Temp\\ipykernel_9128\\3285100105.py\", line 102, in train_STAGATE\n      trainer = STAGATE(hidden_dims1=[X1.shape[1]] + hidden_dims1,hidden_dims2=[X2.shape[1]] + hidden_dims2, z_dim=z_dim,alpha=alpha,\n    File \"C:\\Users\\AGNISH\\AppData\\Local\\Temp\\ipykernel_9128\\709567896.py\", line 30, in __init__\n      self.optimize(self.loss)\n    File \"C:\\Users\\AGNISH\\AppData\\Local\\Temp\\ipykernel_9128\\709567896.py\", line 52, in optimize\n      gradients, variables = zip(*optimizer.compute_gradients(loss))\nNode: 'gradients/SparseTensorDenseMatMul_1/SparseTensorDenseMatMul_grad/GatherV2_1'\nOOM when allocating tensor with shape[6831887,512] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n\t [[{{node gradients/SparseTensorDenseMatMul_1/SparseTensorDenseMatMul_grad/GatherV2_1}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\nOriginal stack trace for 'gradients/SparseTensorDenseMatMul_1/SparseTensorDenseMatMul_grad/GatherV2_1':\n  File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\runpy.py\", line 197, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\runpy.py\", line 87, in _run_code\n    exec(code, run_globals)\n  File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n    app.launch_new_instance()\n  File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n    app.start()\n  File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 725, in start\n    self.io_loop.start()\n  File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n    self.asyncio_loop.run_forever()\n  File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n    self._run_once()\n  File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n    handle._run()\n  File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\asyncio\\events.py\", line 80, in _run\n    self._context.run(self._callback, *self._args)\n  File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 513, in dispatch_queue\n    await self.process_one()\n  File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 502, in process_one\n    await dispatch(*args)\n  File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 409, in dispatch_shell\n    await result\n  File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n    reply_content = await reply_content\n  File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n    res = shell.run_cell(\n  File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 540, in run_cell\n    return super().run_cell(*args, **kwargs)\n  File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3006, in run_cell\n    result = self._run_cell(\n  File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3061, in _run_cell\n    result = runner(coro)\n  File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n    coro.send(None)\n  File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3266, in run_cell_async\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n  File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3445, in run_ast_nodes\n    if await self.run_code(code, result, async_=asy):\n  File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3505, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"C:\\Users\\AGNISH\\AppData\\Local\\Temp\\ipykernel_9128\\2186767892.py\", line 1, in <module>\n    gdata = train_STAGATE(gdata,pdata,n_epochs=500, alpha=0,save_attention=True, save_loss=True)\n  File \"C:\\Users\\AGNISH\\AppData\\Local\\Temp\\ipykernel_9128\\3285100105.py\", line 102, in train_STAGATE\n    trainer = STAGATE(hidden_dims1=[X1.shape[1]] + hidden_dims1,hidden_dims2=[X2.shape[1]] + hidden_dims2, z_dim=z_dim,alpha=alpha,\n  File \"C:\\Users\\AGNISH\\AppData\\Local\\Temp\\ipykernel_9128\\709567896.py\", line 30, in __init__\n    self.optimize(self.loss)\n  File \"C:\\Users\\AGNISH\\AppData\\Local\\Temp\\ipykernel_9128\\709567896.py\", line 52, in optimize\n    gradients, variables = zip(*optimizer.compute_gradients(loss))\n  File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\tensorflow\\python\\training\\optimizer.py\", line 599, in compute_gradients\n    grads = gradients.gradients(\n  File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py\", line 165, in gradients\n    return gradients_util._GradientsHelper(\n  File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py\", line 695, in _GradientsHelper\n    in_grads = _MaybeCompile(grad_scope, op, func_call,\n  File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py\", line 329, in _MaybeCompile\n    return grad_fn()  # Exit early\n  File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py\", line 696, in <lambda>\n    lambda: grad_fn(op, *out_grads))\n  File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\tensorflow\\python\\ops\\sparse_grad.py\", line 198, in _SparseTensorDenseMatMulGrad\n    parts_b = array_ops.gather(\n  File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\", line 150, in error_handler\n    return fn(*args, **kwargs)\n  File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\", line 1176, in op_dispatch_handler\n    return dispatch_target(*args, **kwargs)\n  File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 576, in new_func\n    return func(*args, **kwargs)\n  File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 5326, in gather\n    return gen_array_ops.gather_v2(params, indices, axis, name=name)\n  File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 4768, in gather_v2\n    _, _, _op, _outputs = _op_def_library._apply_op_helper(\n  File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 795, in _apply_op_helper\n    op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n  File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3814, in _create_op_internal\n    ret = Operation(\n\n...which was originally created as op 'SparseTensorDenseMatMul_1/SparseTensorDenseMatMul', defined at:\n  File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\runpy.py\", line 197, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n[elided 21 identical lines from previous traceback]\n  File \"C:\\Users\\AGNISH\\AppData\\Local\\Temp\\ipykernel_9128\\3285100105.py\", line 102, in train_STAGATE\n    trainer = STAGATE(hidden_dims1=[X1.shape[1]] + hidden_dims1,hidden_dims2=[X2.shape[1]] + hidden_dims2, z_dim=z_dim,alpha=alpha,\n  File \"C:\\Users\\AGNISH\\AppData\\Local\\Temp\\ipykernel_9128\\709567896.py\", line 27, in __init__\n    self.loss, self.H, self.C, self.ReX1, self.ReX2 = self.gate(self.A1,self.A2, self.prune_A, self.X1,self.X2)\n  File \"C:\\Users\\AGNISH\\AppData\\Local\\Temp\\ipykernel_9128\\340810500.py\", line 42, in __call__\n    H2 = self.__encoder2(A2, prune_A, H2, layer)\n  File \"C:\\Users\\AGNISH\\AppData\\Local\\Temp\\ipykernel_9128\\340810500.py\", line 119, in __encoder2\n    return tf.sparse.sparse_dense_matmul(self.C2[layer], H)\n  File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\tensorflow\\python\\ops\\sparse_ops.py\", line 2649, in sparse_tensor_dense_matmul\n    return gen_sparse_ops.sparse_tensor_dense_mat_mul(\n  File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\tensorflow\\python\\ops\\gen_sparse_ops.py\", line 3563, in sparse_tensor_dense_mat_mul\n    _, _, _op, _outputs = _op_def_library._apply_op_helper(\n  File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 795, in _apply_op_helper\n    op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n  File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3814, in _create_op_internal\n    ret = Operation(\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1378\u001b[0m, in \u001b[0;36mBaseSession._do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1377\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1378\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs)\n\u001b[0;32m   1379\u001b[0m \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mOpError \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1361\u001b[0m, in \u001b[0;36mBaseSession._do_run.<locals>._run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1360\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_extend_graph()\n\u001b[1;32m-> 1361\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m   1362\u001b[0m                                 target_list, run_metadata)\n",
      "File \u001b[1;32mc:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1454\u001b[0m, in \u001b[0;36mBaseSession._call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1452\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call_tf_sessionrun\u001b[39m(\u001b[39mself\u001b[39m, options, feed_dict, fetch_list, target_list,\n\u001b[0;32m   1453\u001b[0m                         run_metadata):\n\u001b[1;32m-> 1454\u001b[0m   \u001b[39mreturn\u001b[39;00m tf_session\u001b[39m.\u001b[39;49mTF_SessionRun_wrapper(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_session, options, feed_dict,\n\u001b[0;32m   1455\u001b[0m                                           fetch_list, target_list,\n\u001b[0;32m   1456\u001b[0m                                           run_metadata)\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[6831887,512] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n\t [[{{node gradients/SparseTensorDenseMatMul_1/SparseTensorDenseMatMul_grad/GatherV2_1}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m gdata \u001b[39m=\u001b[39m train_STAGATE(gdata,pdata,n_epochs\u001b[39m=\u001b[39;49m\u001b[39m500\u001b[39;49m, alpha\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,save_attention\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, save_loss\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "Cell \u001b[1;32mIn[14], line 113\u001b[0m, in \u001b[0;36mtrain_STAGATE\u001b[1;34m(adata1, adata2, hidden_dims1, hidden_dims2, z_dim, alpha, n_epochs, lr, key_added, gradient_clipping, nonlinear, weight_decay, verbose, random_seed, pre_labels, pre_resolution, save_attention, save_loss, save_reconstrction)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[39m#explain the code from here\u001b[39;00m\n\u001b[0;32m    112\u001b[0m \u001b[39mif\u001b[39;00m alpha \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m--> 113\u001b[0m     trainer(G_tf1, G_tf2, G_tf1, X1,X2)\n\u001b[0;32m    114\u001b[0m     embeddings, attentions, loss, ReX1, ReX2\u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39minfer(G_tf1, G_tf2, G_tf1, X1,X2)\n\u001b[0;32m    115\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "Cell \u001b[1;32mIn[13], line 58\u001b[0m, in \u001b[0;36mSTAGATE.__call__\u001b[1;34m(self, A1, A2, prune_A, X1, X2)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, A1, A2, prune_A, X1, X2):\n\u001b[0;32m     57\u001b[0m     \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_epochs):\n\u001b[1;32m---> 58\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_epoch(epoch, A1, A2, prune_A, X1, X2)\n",
      "Cell \u001b[1;32mIn[13], line 65\u001b[0m, in \u001b[0;36mSTAGATE.run_epoch\u001b[1;34m(self, epoch, A1, A2, prune_A, X1, X2)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_epoch\u001b[39m(\u001b[39mself\u001b[39m, epoch, A1,A2 ,prune_A, X1,X2):\n\u001b[1;32m---> 65\u001b[0m     loss, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msession\u001b[39m.\u001b[39;49mrun([\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloss, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_op],\n\u001b[0;32m     66\u001b[0m                        feed_dict\u001b[39m=\u001b[39;49m{\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mA1: A1,\n\u001b[0;32m     67\u001b[0m                                   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mA2: A2,\n\u001b[0;32m     68\u001b[0m                                   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprune_A: prune_A,\n\u001b[0;32m     69\u001b[0m                                   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mX1: X1,\n\u001b[0;32m     70\u001b[0m                                   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mX2: X2})\n\u001b[0;32m     72\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss_list\u001b[39m.\u001b[39mappend(loss)\n\u001b[0;32m     73\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose:\n",
      "File \u001b[1;32mc:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\tensorflow\\python\\client\\session.py:968\u001b[0m, in \u001b[0;36mBaseSession.run\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    965\u001b[0m run_metadata_ptr \u001b[39m=\u001b[39m tf_session\u001b[39m.\u001b[39mTF_NewBuffer() \u001b[39mif\u001b[39;00m run_metadata \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    967\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 968\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(\u001b[39mNone\u001b[39;49;00m, fetches, feed_dict, options_ptr,\n\u001b[0;32m    969\u001b[0m                      run_metadata_ptr)\n\u001b[0;32m    970\u001b[0m   \u001b[39mif\u001b[39;00m run_metadata:\n\u001b[0;32m    971\u001b[0m     proto_data \u001b[39m=\u001b[39m tf_session\u001b[39m.\u001b[39mTF_GetBuffer(run_metadata_ptr)\n",
      "File \u001b[1;32mc:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1191\u001b[0m, in \u001b[0;36mBaseSession._run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1188\u001b[0m \u001b[39m# We only want to really perform the run if fetches or targets are provided,\u001b[39;00m\n\u001b[0;32m   1189\u001b[0m \u001b[39m# or if the call is a partial run that specifies feeds.\u001b[39;00m\n\u001b[0;32m   1190\u001b[0m \u001b[39mif\u001b[39;00m final_fetches \u001b[39mor\u001b[39;00m final_targets \u001b[39mor\u001b[39;00m (handle \u001b[39mand\u001b[39;00m feed_dict_tensor):\n\u001b[1;32m-> 1191\u001b[0m   results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_run(handle, final_targets, final_fetches,\n\u001b[0;32m   1192\u001b[0m                          feed_dict_tensor, options, run_metadata)\n\u001b[0;32m   1193\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1194\u001b[0m   results \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1371\u001b[0m, in \u001b[0;36mBaseSession._do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1368\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_tf_sessionprun(handle, feed_dict, fetch_list)\n\u001b[0;32m   1370\u001b[0m \u001b[39mif\u001b[39;00m handle \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1371\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m   1372\u001b[0m                        run_metadata)\n\u001b[0;32m   1373\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1374\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_do_call(_prun_fn, handle, feeds, fetches)\n",
      "File \u001b[1;32mc:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1397\u001b[0m, in \u001b[0;36mBaseSession._do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1392\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39monly supports NHWC tensor format\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m message:\n\u001b[0;32m   1393\u001b[0m   message \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mA possible workaround: Try disabling Grappler optimizer\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   1394\u001b[0m               \u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mby modifying the config for creating the session eg.\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   1395\u001b[0m               \u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39msession_config.graph_options.rewrite_options.\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   1396\u001b[0m               \u001b[39m'\u001b[39m\u001b[39mdisable_meta_optimizer = True\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m-> 1397\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mtype\u001b[39m(e)(node_def, op, message)\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'gradients/SparseTensorDenseMatMul_1/SparseTensorDenseMatMul_grad/GatherV2_1' defined at (most recent call last):\n    File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n      app.start()\n    File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 725, in start\n      self.io_loop.start()\n    File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3006, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3061, in _run_cell\n      result = runner(coro)\n    File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3266, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3445, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3505, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\AGNISH\\AppData\\Local\\Temp\\ipykernel_9128\\2186767892.py\", line 1, in <module>\n      gdata = train_STAGATE(gdata,pdata,n_epochs=500, alpha=0,save_attention=True, save_loss=True)\n    File \"C:\\Users\\AGNISH\\AppData\\Local\\Temp\\ipykernel_9128\\3285100105.py\", line 102, in train_STAGATE\n      trainer = STAGATE(hidden_dims1=[X1.shape[1]] + hidden_dims1,hidden_dims2=[X2.shape[1]] + hidden_dims2, z_dim=z_dim,alpha=alpha,\n    File \"C:\\Users\\AGNISH\\AppData\\Local\\Temp\\ipykernel_9128\\709567896.py\", line 30, in __init__\n      self.optimize(self.loss)\n    File \"C:\\Users\\AGNISH\\AppData\\Local\\Temp\\ipykernel_9128\\709567896.py\", line 52, in optimize\n      gradients, variables = zip(*optimizer.compute_gradients(loss))\nNode: 'gradients/SparseTensorDenseMatMul_1/SparseTensorDenseMatMul_grad/GatherV2_1'\nOOM when allocating tensor with shape[6831887,512] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n\t [[{{node gradients/SparseTensorDenseMatMul_1/SparseTensorDenseMatMul_grad/GatherV2_1}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\nOriginal stack trace for 'gradients/SparseTensorDenseMatMul_1/SparseTensorDenseMatMul_grad/GatherV2_1':\n  File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\runpy.py\", line 197, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\runpy.py\", line 87, in _run_code\n    exec(code, run_globals)\n  File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n    app.launch_new_instance()\n  File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n    app.start()\n  File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 725, in start\n    self.io_loop.start()\n  File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n    self.asyncio_loop.run_forever()\n  File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n    self._run_once()\n  File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n    handle._run()\n  File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\asyncio\\events.py\", line 80, in _run\n    self._context.run(self._callback, *self._args)\n  File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 513, in dispatch_queue\n    await self.process_one()\n  File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 502, in process_one\n    await dispatch(*args)\n  File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 409, in dispatch_shell\n    await result\n  File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n    reply_content = await reply_content\n  File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n    res = shell.run_cell(\n  File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 540, in run_cell\n    return super().run_cell(*args, **kwargs)\n  File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3006, in run_cell\n    result = self._run_cell(\n  File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3061, in _run_cell\n    result = runner(coro)\n  File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n    coro.send(None)\n  File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3266, in run_cell_async\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n  File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3445, in run_ast_nodes\n    if await self.run_code(code, result, async_=asy):\n  File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3505, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"C:\\Users\\AGNISH\\AppData\\Local\\Temp\\ipykernel_9128\\2186767892.py\", line 1, in <module>\n    gdata = train_STAGATE(gdata,pdata,n_epochs=500, alpha=0,save_attention=True, save_loss=True)\n  File \"C:\\Users\\AGNISH\\AppData\\Local\\Temp\\ipykernel_9128\\3285100105.py\", line 102, in train_STAGATE\n    trainer = STAGATE(hidden_dims1=[X1.shape[1]] + hidden_dims1,hidden_dims2=[X2.shape[1]] + hidden_dims2, z_dim=z_dim,alpha=alpha,\n  File \"C:\\Users\\AGNISH\\AppData\\Local\\Temp\\ipykernel_9128\\709567896.py\", line 30, in __init__\n    self.optimize(self.loss)\n  File \"C:\\Users\\AGNISH\\AppData\\Local\\Temp\\ipykernel_9128\\709567896.py\", line 52, in optimize\n    gradients, variables = zip(*optimizer.compute_gradients(loss))\n  File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\tensorflow\\python\\training\\optimizer.py\", line 599, in compute_gradients\n    grads = gradients.gradients(\n  File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py\", line 165, in gradients\n    return gradients_util._GradientsHelper(\n  File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py\", line 695, in _GradientsHelper\n    in_grads = _MaybeCompile(grad_scope, op, func_call,\n  File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py\", line 329, in _MaybeCompile\n    return grad_fn()  # Exit early\n  File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py\", line 696, in <lambda>\n    lambda: grad_fn(op, *out_grads))\n  File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\tensorflow\\python\\ops\\sparse_grad.py\", line 198, in _SparseTensorDenseMatMulGrad\n    parts_b = array_ops.gather(\n  File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\", line 150, in error_handler\n    return fn(*args, **kwargs)\n  File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\", line 1176, in op_dispatch_handler\n    return dispatch_target(*args, **kwargs)\n  File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 576, in new_func\n    return func(*args, **kwargs)\n  File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 5326, in gather\n    return gen_array_ops.gather_v2(params, indices, axis, name=name)\n  File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 4768, in gather_v2\n    _, _, _op, _outputs = _op_def_library._apply_op_helper(\n  File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 795, in _apply_op_helper\n    op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n  File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3814, in _create_op_internal\n    ret = Operation(\n\n...which was originally created as op 'SparseTensorDenseMatMul_1/SparseTensorDenseMatMul', defined at:\n  File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\runpy.py\", line 197, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n[elided 21 identical lines from previous traceback]\n  File \"C:\\Users\\AGNISH\\AppData\\Local\\Temp\\ipykernel_9128\\3285100105.py\", line 102, in train_STAGATE\n    trainer = STAGATE(hidden_dims1=[X1.shape[1]] + hidden_dims1,hidden_dims2=[X2.shape[1]] + hidden_dims2, z_dim=z_dim,alpha=alpha,\n  File \"C:\\Users\\AGNISH\\AppData\\Local\\Temp\\ipykernel_9128\\709567896.py\", line 27, in __init__\n    self.loss, self.H, self.C, self.ReX1, self.ReX2 = self.gate(self.A1,self.A2, self.prune_A, self.X1,self.X2)\n  File \"C:\\Users\\AGNISH\\AppData\\Local\\Temp\\ipykernel_9128\\340810500.py\", line 42, in __call__\n    H2 = self.__encoder2(A2, prune_A, H2, layer)\n  File \"C:\\Users\\AGNISH\\AppData\\Local\\Temp\\ipykernel_9128\\340810500.py\", line 119, in __encoder2\n    return tf.sparse.sparse_dense_matmul(self.C2[layer], H)\n  File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\tensorflow\\python\\ops\\sparse_ops.py\", line 2649, in sparse_tensor_dense_matmul\n    return gen_sparse_ops.sparse_tensor_dense_mat_mul(\n  File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\tensorflow\\python\\ops\\gen_sparse_ops.py\", line 3563, in sparse_tensor_dense_mat_mul\n    _, _, _op, _outputs = _op_def_library._apply_op_helper(\n  File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 795, in _apply_op_helper\n    op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n  File \"c:\\Users\\AGNISH\\.conda\\envs\\STAGATE\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3814, in _create_op_internal\n    ret = Operation(\n"
     ]
    }
   ],
   "source": [
    "gdata = train_STAGATE(gdata,pdata,n_epochs=500, alpha=0,save_attention=True, save_loss=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "STAGATE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
